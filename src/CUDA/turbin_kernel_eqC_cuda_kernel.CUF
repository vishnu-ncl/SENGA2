!
! auto-generated by ops_fortran.py
!
MODULE TURBIN_KERNEL_EQC_MODULE
USE OPS_FORTRAN_DECLARATIONS
USE OPS_FORTRAN_RT_SUPPORT

USE OPS_CONSTANTS
USE ISO_C_BINDING
USE CUDAFOR

real(8), DIMENSION(:), DEVICE, ALLOCATABLE :: reductionArrayDevice3_turbin_kernel_eqC
INTEGER(KIND=4), constant :: xdim1_turbin_kernel_eqC
INTEGER(KIND=4):: xdim1_turbin_kernel_eqC_h  = -1
INTEGER(KIND=4), constant :: ydim1_turbin_kernel_eqC
INTEGER(KIND=4):: ydim1_turbin_kernel_eqC_h  = -1
INTEGER(KIND=4), constant :: zdim1_turbin_kernel_eqC
INTEGER(KIND=4):: zdim1_turbin_kernel_eqC_h  = -1
#define OPS_ACC1(x,y,z) (x+xdim1_turbin_kernel_eqC*(y)+xdim1_turbin_kernel_eqC*ydim1_turbin_kernel_eqC*(z)+1)


contains

!Reduction cuda kernel
attributes (device) SUBROUTINE ReductionFloat8(sharedDouble8, reductionResult,inputValue,reductionOperation)
  REAL(kind=8), DIMENSION(:), DEVICE :: reductionResult
  REAL(kind=8) :: inputValue
  INTEGER(kind=4), VALUE :: reductionOperation
  REAL(kind=8), DIMENSION(0:*) :: sharedDouble8
  INTEGER(kind=4) :: i1
  INTEGER(kind=4) :: threadID
  threadID = (threadIdx%y-1)*blockDim%x + (threadIdx%x - 1)
  i1 = ishft(blockDim%x*blockDim%y,-1)
  CALL syncthreads()
  sharedDouble8(threadID) = inputValue
  DO WHILE (i1 > 0 )
    CALL syncthreads()
    IF (threadID < i1) THEN
      SELECT CASE(reductionOperation)
      CASE (0)
      sharedDouble8(threadID) = sharedDouble8(threadID) + sharedDouble8(threadID + i1)
      CASE (1)
      IF (sharedDouble8(threadID + i1) < sharedDouble8(threadID)) THEN
        sharedDouble8(threadID) = sharedDouble8(threadID + i1)
      ENDIF
      CASE (2)
      IF (sharedDouble8(threadID + i1) > sharedDouble8(threadID)) THEN
        sharedDouble8(threadID) = sharedDouble8(threadID + i1)
      ENDIF
      END SELECT
    ENDIF
    i1 = ishft(i1,-1)
  END DO
  CALL syncthreads()
  IF (threadID .EQ. 0) THEN
    SELECT CASE(reductionOperation)
    CASE (0)
    reductionResult(1) = reductionResult(1) + sharedDouble8(0)
    CASE (1)
    IF (sharedDouble8(0) < reductionResult(1)) THEN
      reductionResult(1) = sharedDouble8(0)
    ENDIF
    CASE (2)
    IF (sharedDouble8(0) > reductionResult(1)) THEN
      reductionResult(1) = sharedDouble8(0)
    ENDIF
    END SELECT
  ENDIF
  CALL syncthreads()
  END SUBROUTINE

  attributes (device) SUBROUTINE ReductionInt4(sharedInt4, reductionResult,inputValue,reductionOperation)
  INTEGER(kind=4), DIMENSION(:), DEVICE :: reductionResult
  INTEGER(kind=4) :: inputValue
  INTEGER(kind=4), VALUE :: reductionOperation
  INTEGER(kind=4), DIMENSION(0:*) :: sharedInt4
  INTEGER(kind=4) :: i1
  INTEGER(kind=4) :: threadID
  threadID = (threadIdx%y-1)*blockDim%x + (threadIdx%x - 1)
  i1 = ishft(blockDim%x*blockDim%y,-1)
  CALL syncthreads()
  sharedInt4(threadID) = inputValue
  DO WHILE (i1 > 0 )
    CALL syncthreads()
    IF (threadID < i1) THEN
      SELECT CASE(reductionOperation)
      CASE (0)
      sharedInt4(threadID) = sharedInt4(threadID) + sharedInt4(threadID + i1)
      CASE (1)
      IF (sharedInt4(threadID + i1) < sharedInt4(threadID)) THEN
        sharedInt4(threadID) = sharedInt4(threadID + i1)
      ENDIF
      CASE (2)
      IF (sharedInt4(threadID + i1) > sharedInt4(threadID)) THEN
        sharedInt4(threadID) = sharedInt4(threadID + i1)
      ENDIF
      END SELECT
    ENDIF
    i1 = ishft(i1,-1)
  END DO
  CALL syncthreads()
  IF (threadID .EQ. 0) THEN
    SELECT CASE(reductionOperation)
    CASE (0)
    reductionResult(1) = reductionResult(1) + sharedInt4(0)
    CASE (1)
    IF (sharedInt4(0) < reductionResult(1)) THEN
      reductionResult(1) = sharedInt4(0)
    ENDIF
    CASE (2)
    IF (sharedInt4(0) > reductionResult(1)) THEN
      reductionResult(1) = sharedInt4(0)
    ENDIF
    END SELECT
  ENDIF
  CALL syncthreads()
END SUBROUTINE

!user function
attributes (device) SUBROUTINE turbin_kernel_eqc_gpu(in_arr, val1, reduction_var)
    use data_types
    implicit none

    real(kind=8), dimension(1), intent(in) :: in_arr
    real(kind=8), intent(in) :: val1
    real(kind=8) :: reduction_var
    real(kind=8) :: fornow

    fornow = in_arr(OPS_ACC1(0,0,0)) - val1

    reduction_var = reduction_var + fornow*fornow

END SUBROUTINE

#undef OPS_ACC1



!CUDA kernel function -- wrapper calling user kernel
attributes (global) subroutine turbin_kernel_eqC_wrap( &
& opsDat1Local, &
& opsGblDat2Device,   &
& reductionArrayDevice3,   &
& dat1_base, &
& size1, size2, size3 )
  IMPLICIT NONE
  real(8), DEVICE, INTENT(IN) :: opsDat1Local(*)
  integer(4) arg1
  real(8), VALUE :: opsGblDat2Device
  real(8), DIMENSION(:), DEVICE :: reductionArrayDevice3
  real(8) :: opsGblDat3Device
  real(8), DIMENSION(0:*), SHARED :: sharedMem
  integer(4), value :: dat1_base
  integer(4) start(3)
  integer(4) end(3)
  integer, value :: size1,size2,size3
  integer n_x, n_y, n_z


  n_z = blockDim%z * (blockIdx%z-1) + threadIdx%z
  n_y = blockDim%y * (blockIdx%y-1) + threadIdx%y
  n_x = blockDim%x * (blockIdx%x-1) + threadIdx%x

  arg1 = (n_x-1) * 1*1 + (n_y-1) * 1*1 * xdim1_turbin_kernel_eqC + (n_z-1) * 1*1 * xdim1_turbin_kernel_eqC * ydim1_turbin_kernel_eqC
  opsGblDat3Device = 0.0_8
  IF ((n_x-1) < size1 .AND. (n_y-1) < size2 .AND. (n_z-1) < size3) THEN
    call turbin_kernel_eqC_gpu( &
    & opsDat1Local(dat1_base+arg1), &
    & opsGblDat2Device, &
    & opsGblDat3Device )

  ENDIF

  call ReductionFloat8(sharedMem, reductionArrayDevice3((blockIdx%z - 1)*gridDim%y*gridDim%x + (blockIdx%y - 1)*gridDim%x + (blockIdx%x-1) + 1:),opsGblDat3Device,0)

end subroutine

!host subroutine
attributes (host) subroutine turbin_kernel_eqC_host( userSubroutine, block, dim, range, &
& opsArg1, &
& opsArg2, &
& opsArg3)
  use cudafor
  IMPLICIT NONE
  character(kind=c_char,len=*), INTENT(IN) :: userSubroutine
  type ( ops_block ), INTENT(IN) :: block
  integer(kind=4), INTENT(IN):: dim
  integer(kind=4)   , DIMENSION(2*dim), INTENT(IN) :: range
  real(kind=8) t1,t2,t3
  real(kind=4) transfer_total, transfer
  integer(kind=4) :: istat

  type ( ops_arg )  , INTENT(IN) :: opsArg1
  real(8), DIMENSION(:), DEVICE, POINTER  :: opsDat1Local
  integer(kind=4) :: opsDat1Cardinality
  integer(kind=4), POINTER, DIMENSION(:)  :: dat1_size
  integer(kind=4) :: dat1_base
  INTEGER(KIND=4) :: xdim1
  INTEGER(KIND=4) :: ydim1, zdim1

  type ( ops_arg )  , INTENT(IN) :: opsArg2
  integer(kind=4) :: opsDat2Cardinality
  real(8), DIMENSION(:), POINTER :: opsDat2Host
  type ( ops_arg )  , INTENT(IN) :: opsArg3
  integer(kind=4) :: opsDat3Cardinality
  real(8), DIMENSION(:), POINTER :: opsDat3Host
  real(8), DIMENSION(:), ALLOCATABLE :: reductionArrayHost3
  INTEGER(kind=4) :: reductionCardinality3

  integer x_size, y_size, z_size
  integer start(3)
  integer end(3)
  integer(kind=4) :: n
  integer(kind=4) :: i10
  integer(kind=4) :: i20
  integer(kind=4) :: blocksPerGrid
  integer(kind=4) :: nshared
  integer(kind=4) :: nthread

  !cuda grid and thread block sizes
  type(dim3) :: grid, tblock

  type ( ops_arg ) , DIMENSION(3) :: opsArgArray

  opsArgArray(1) = opsArg1
  opsArgArray(2) = opsArg2
  opsArgArray(3) = opsArg3

  call setKernelTime(533,userSubroutine//char(0),0.0_8,0.0_8,0.0_4,1)
  call ops_timers_core(t1)

#ifdef OPS_MPI
  IF (getRange(block, start, end, range) < 0) THEN
    return
  ENDIF
#else
  DO n = 1, 3
    start(n) = range(2*n-1)
    end(n) = range(2*n)
  END DO
#endif


  x_size = MAX(0,end(1)-start(1)+1)
  y_size = MAX(0,end(2)-start(2)+1)
  z_size = MAX(0,end(3)-start(3)+1)

  call c_f_pointer(getDatSizeFromOpsArg(opsArg1),dat1_size,(/dim/))
  xdim1 = dat1_size(1)
  ydim1 = dat1_size(2)
  zdim1 = dat1_size(3)
  opsDat1Cardinality = opsArg1%dim * xdim1 * ydim1 * zdim1
  dat1_base = getDatBaseFromOpsArg3D(opsArg1,start,1)
  call c_f_pointer(opsArg1%data_d,opsDat1Local,(/opsDat1Cardinality/))

  opsDat2Cardinality = opsArg2%dim
  call c_f_pointer(opsArg2%data,opsDat2Host,(/opsDat2Cardinality/))

  opsDat3Cardinality = opsArg3%dim
  call c_f_pointer(getReductionPtrFromOpsArg(opsArg3,block),opsDat3Host,(/opsDat3Cardinality/))

  IF ((xdim1 .NE. xdim1_turbin_kernel_eqC_h) .OR. &
  (ydim1 .NE. ydim1_turbin_kernel_eqC_h) ) THEN
    xdim1_turbin_kernel_eqC = xdim1
    xdim1_turbin_kernel_eqC_h = xdim1
    ydim1_turbin_kernel_eqC = ydim1
    ydim1_turbin_kernel_eqC_h = ydim1
  ENDIF

  grid = dim3( (x_size-1)/getOPS_block_size_x()+ 1, (y_size-1)/getOPS_block_size_y() + 1, z_size)
  tblock = dim3(getOPS_block_size_x(),getOPS_block_size_y(),1)

  !Reduction vars and shared memory for reductions
  nshared = 0
  nthread = getOPS_block_size_x()*getOPS_block_size_y()
  blocksPerGrid = ((x_size-1)/getOPS_block_size_x()+ 1)*((y_size-1)/getOPS_block_size_y() + 1)* z_size

  nshared = MAX(nshared,8*1*nthread)

  reductionCardinality3 = blocksPerGrid * 1
  allocate( reductionArrayHost3(reductionCardinality3* (1)) )
  IF (.not. allocated(reductionArrayDevice3_turbin_kernel_eqC)) THEN
    allocate( reductionArrayDevice3_turbin_kernel_eqC(reductionCardinality3* (1)) )
  ENDIF

  DO i10 = 0, reductionCardinality3-1
    reductionArrayHost3(i10+1) = 0.0
  END DO

  reductionArrayDevice3_turbin_kernel_eqC = reductionArrayHost3

  !halo exchanges
  call ops_H_D_exchanges_device(opsArgArray,3)
  call ops_halo_exchanges(opsArgArray,3,range)
  call ops_H_D_exchanges_device(opsArgArray,3)

  call ops_timers_core(t2)
  call turbin_kernel_eqC_wrap <<<grid,tblock,nshared>>> (&
  & opsDat1Local, &
  & opsDat2Host(1), &
  & reductionArrayDevice3_turbin_kernel_eqC, &
  & dat1_base, &
  & x_size, y_size, z_size )

  reductionArrayHost3 = reductionArrayDevice3_turbin_kernel_eqC

  DO i10 = 0, reductionCardinality3-1
    opsDat3Host = opsDat3Host + reductionArrayHost3(i10+1)
  END DO

  deallocate( reductionArrayHost3 )
  istat = cudaDeviceSynchronize()
  call ops_timers_core(t3)
  call ops_set_dirtybit_device(opsArgArray, 3)

  !Timing and data movement
  transfer_total = 0.0_4
  call ops_compute_transfer(3, start, end, opsArg1,transfer)
  transfer_total = transfer_total + transfer
  call setKernelTime(533,userSubroutine,t3-t2,t2-t1,transfer_total,0)
end subroutine
END MODULE
