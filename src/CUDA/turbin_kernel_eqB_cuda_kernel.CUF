!
! auto-generated by ops_fortran.py
!

MODULE TURBIN_KERNEL_EQB_MODULE
USE OPS_FORTRAN_DECLARATIONS
USE OPS_FORTRAN_RT_SUPPORT

USE OPS_CONSTANTS
USE ISO_C_BINDING
USE CUDAFOR

real(kind=8), dimension(:), device, allocatable :: reductionArrayDevice2_turbin_kernel_eqB
integer(4), constant :: xdim1_turbin_kernel_eqB
integer(4):: xdim1_turbin_kernel_eqB_h  = -1
integer(4), constant :: ydim1_turbin_kernel_eqB
integer(4):: ydim1_turbin_kernel_eqB_h  = -1
#define OPS_ACC1(x,y,z) (x+xdim1_turbin_kernel_eqB*(y)+xdim1_turbin_kernel_eqB*ydim1_turbin_kernel_eqB*(z)+1)


contains

!Reduction cuda kernel
attributes (device) SUBROUTINE ReductionFloat8(sharedDouble8, reductionResult,inputValue,reductionOperation)
  REAL(8), dimension(:), DEVICE :: reductionResult
  REAL(8) :: inputValue
  integer(4), VALUE :: reductionOperation
  REAL(8), dimension(0:*) :: sharedDouble8
  integer(4) :: i1
  integer(4) :: threadID
  threadID = (threadIdx%y-1)*blockDim%x + (threadIdx%x - 1)
  i1 = ishft(blockDim%x*blockDim%y,-1)
  CALL syncthreads()
  sharedDouble8(threadID) = inputValue
  DO WHILE (i1 > 0 )
    CALL syncthreads()
    IF (threadID < i1) THEN
      SELECT CASE(reductionOperation)
      CASE (0)
      sharedDouble8(threadID) = sharedDouble8(threadID) + sharedDouble8(threadID + i1)
      CASE (1)
      IF (sharedDouble8(threadID + i1) < sharedDouble8(threadID)) THEN
        sharedDouble8(threadID) = sharedDouble8(threadID + i1)
      ENDIF
      CASE (2)
      IF (sharedDouble8(threadID + i1) > sharedDouble8(threadID)) THEN
        sharedDouble8(threadID) = sharedDouble8(threadID + i1)
      ENDIF
      END SELECT
    ENDIF
    i1 = ishft(i1,-1)
  END DO
  CALL syncthreads()
  IF (threadID .EQ. 0) THEN
    SELECT CASE(reductionOperation)
    CASE (0)
    reductionResult(1) = reductionResult(1) + sharedDouble8(0)
    CASE (1)
    IF (sharedDouble8(0) < reductionResult(1)) THEN
      reductionResult(1) = sharedDouble8(0)
    ENDIF
    CASE (2)
    IF (sharedDouble8(0) > reductionResult(1)) THEN
      reductionResult(1) = sharedDouble8(0)
    ENDIF
    END SELECT
  ENDIF
  CALL syncthreads()
  END SUBROUTINE

  attributes (device) SUBROUTINE ReductionInt4(sharedInt4, reductionResult,inputValue,reductionOperation)
  integer(4), dimension(:), DEVICE :: reductionResult
  integer(4) :: inputValue
  integer(4), VALUE :: reductionOperation
  integer(4), dimension(0:*) :: sharedInt4
  integer(4) :: i1
  integer(4) :: threadID
  threadID = (threadIdx%y-1)*blockDim%x + (threadIdx%x - 1)
  i1 = ishft(blockDim%x*blockDim%y,-1)
  CALL syncthreads()
  sharedInt4(threadID) = inputValue
  DO WHILE (i1 > 0 )
    CALL syncthreads()
    IF (threadID < i1) THEN
      SELECT CASE(reductionOperation)
      CASE (0)
      sharedInt4(threadID) = sharedInt4(threadID) + sharedInt4(threadID + i1)
      CASE (1)
      IF (sharedInt4(threadID + i1) < sharedInt4(threadID)) THEN
        sharedInt4(threadID) = sharedInt4(threadID + i1)
      ENDIF
      CASE (2)
      IF (sharedInt4(threadID + i1) > sharedInt4(threadID)) THEN
        sharedInt4(threadID) = sharedInt4(threadID + i1)
      ENDIF
      END SELECT
    ENDIF
    i1 = ishft(i1,-1)
  END DO
  CALL syncthreads()
  IF (threadID .EQ. 0) THEN
    SELECT CASE(reductionOperation)
    CASE (0)
    reductionResult(1) = reductionResult(1) + sharedInt4(0)
    CASE (1)
    IF (sharedInt4(0) < reductionResult(1)) THEN
      reductionResult(1) = sharedInt4(0)
    ENDIF
    CASE (2)
    IF (sharedInt4(0) > reductionResult(1)) THEN
      reductionResult(1) = sharedInt4(0)
    ENDIF
    END SELECT
  ENDIF
  CALL syncthreads()
END SUBROUTINE

!user function
attributes (device) SUBROUTINE turbin_kernel_eqb_gpu(in_arr, reduction_var)
    use data_types
    implicit none

    real(kind=8), dimension(1), intent(in) :: in_arr
    real(kind=8) :: reduction_var

    reduction_var = reduction_var + in_arr(OPS_ACC1(0,0,0))

END SUBROUTINE

#undef OPS_ACC1


!CUDA kernel function -- wrapper calling user kernel
attributes (global) subroutine turbin_kernel_eqB_wrap( &
& opsDat1Local, &
& reductionArrayDevice2,   &
& dat1_base, &
& size1, size2, size3 )

  IMPLICIT NONE

  real(kind=8), device, dimension(*), intent(in)    :: opsDat1Local
  integer(4) :: arg1
  real(kind=8), dimension(:), device :: reductionArrayDevice2
  real(kind=8) :: opsGblDat2Device
  real(kind=8), dimension(0:*), shared :: sharedMem
  integer(4), value :: dat1_base
  integer(4), value :: size1, size2, size3
  integer(4)        :: n_x, n_y, n_z


  n_z = blockDim%z * (blockIdx%z-1) + threadIdx%z
  n_y = blockDim%y * (blockIdx%y-1) + threadIdx%y
  n_x = blockDim%x * (blockIdx%x-1) + threadIdx%x

  arg1 = (n_x-1) * 1*1 + (n_y-1) * 1*1 * xdim1_turbin_kernel_eqB + (n_z-1) * 1*1 * xdim1_turbin_kernel_eqB * ydim1_turbin_kernel_eqB
  opsGblDat2Device = 0.0_8
  IF ((n_x-1) < size1 .AND. (n_y-1) < size2 .AND. (n_z-1) < size3) THEN

    call turbin_kernel_eqB_gpu( &
    & opsDat1Local(dat1_base+arg1), &
    & opsGblDat2Device )

  ENDIF

  call ReductionFloat8(sharedMem, reductionArrayDevice2((blockIdx%z - 1)*gridDim%y*gridDim%x + (blockIdx%y - 1)*gridDim%x + (blockIdx%x-1) + 1:),opsGblDat2Device,0)

end subroutine

!host subroutine
attributes (host) subroutine turbin_kernel_eqB_host( userSubroutine, block, dim, range, &
& opsArg1, &
& opsArg2)

  USE CUDAFOR
  IMPLICIT NONE

  character(kind=c_char,len=*), intent(in) :: userSubroutine
  type(ops_block), intent(in) :: block
  integer(4), intent(in):: dim
  integer(4), dimension(2*dim), intent(in) :: range
  real(8) :: t1,t2,t3
  real(4) :: transfer_total, transfer
  integer(4) :: istat

  type(ops_arg), intent(in) :: opsArg1
  real(kind=8), dimension(:), device, pointer  :: opsDat1Local
  integer(4) :: opsDat1Cardinality
  integer(4), pointer, dimension(:) :: dat1_size
  integer(4) :: dat1_base
  integer(4) :: xdim1
  integer(4) :: ydim1, zdim1

  type(ops_arg), intent(in) :: opsArg2
  integer(4) :: opsDat2Cardinality
  real(kind=8), dimension(:), pointer :: opsDat2Host
  real(kind=8), dimension(:), allocatable :: reductionArrayHost2
  integer(4) :: reductionCardinality2

  integer(4) :: x_size, y_size, z_size
  integer(4), dimension(3) :: start_indx, end_indx
  integer(4) :: n
  integer(4) :: i10
  integer(4) :: i20
  integer(4) :: blocksPerGrid
  integer(4) :: nshared
  integer(4) :: nthread

  !cuda grid and thread block sizes
  type(dim3) :: grid, tblock

  type(ops_arg), dimension(2) :: opsArgArray

  opsArgArray(1) = opsArg1
  opsArgArray(2) = opsArg2

  call setKernelTime(522,userSubroutine//char(0),0.0_8,0.0_8,0.0_4,1)
  call ops_timers_core(t1)

#ifdef OPS_MPI
  IF (getRange(block, start_indx, end_indx, range) < 0) THEN
    return
  ENDIF
#else
  DO n = 1, 3
    start_indx(n) = range(2*n-1)
    end_indx(n)   = range(2*n)
  END DO
#endif


  x_size = MAX(0,end_indx(1)-start_indx(1)+1)
  y_size = MAX(0,end_indx(2)-start_indx(2)+1)
  z_size = MAX(0,end_indx(3)-start_indx(3)+1)

  call c_f_pointer(getDatSizeFromOpsArg(opsArg1),dat1_size,(/dim/))
  xdim1 = dat1_size(1)
  ydim1 = dat1_size(2)
  zdim1 = dat1_size(3)
  opsDat1Cardinality = opsArg1%dim * xdim1 * ydim1 * zdim1
  dat1_base = getDatBaseFromOpsArg3D(opsArg1,start_indx,1)
  call c_f_pointer(opsArg1%data_d,opsDat1Local,(/opsDat1Cardinality/))

  opsDat2Cardinality = opsArg2%dim
  call c_f_pointer(getReductionPtrFromOpsArg(opsArg2,block),opsDat2Host,(/opsDat2Cardinality/))

  IF ((xdim1 .NE. xdim1_turbin_kernel_eqB_h) .OR. &
  (ydim1 .NE. ydim1_turbin_kernel_eqB_h) ) THEN
    xdim1_turbin_kernel_eqB = xdim1
    xdim1_turbin_kernel_eqB_h = xdim1
    ydim1_turbin_kernel_eqB = ydim1
    ydim1_turbin_kernel_eqB_h = ydim1
  ENDIF

  grid = dim3( (x_size-1)/getOPS_block_size_x()+ 1, (y_size-1)/getOPS_block_size_y() + 1, z_size)
  tblock = dim3(getOPS_block_size_x(),getOPS_block_size_y(),1)

  !Reduction vars and shared memory for reductions
  nshared = 0
  nthread = getOPS_block_size_x()*getOPS_block_size_y()
  blocksPerGrid = ((x_size-1)/getOPS_block_size_x()+ 1)*((y_size-1)/getOPS_block_size_y() + 1)* z_size

  nshared = MAX(nshared,8*1*nthread)

  reductionCardinality2 = blocksPerGrid * 1
  allocate( reductionArrayHost2(reductionCardinality2* (1)) )
  IF (.not. allocated(reductionArrayDevice2_turbin_kernel_eqB)) THEN
    allocate( reductionArrayDevice2_turbin_kernel_eqB(reductionCardinality2* (1)) )
  ENDIF

  DO i10 = 0, reductionCardinality2-1
    reductionArrayHost2(i10+1) = 0.0
  END DO

  reductionArrayDevice2_turbin_kernel_eqB = reductionArrayHost2

  !halo exchanges
  call ops_H_D_exchanges_device(opsArgArray,2)
  call ops_halo_exchanges(opsArgArray,2,range)
  call ops_H_D_exchanges_device(opsArgArray,2)

  call ops_timers_core(t2)

  call turbin_kernel_eqB_wrap <<<grid,tblock,nshared>>> (&
  & opsDat1Local, &
  & reductionArrayDevice2_turbin_kernel_eqB, &
  & dat1_base, &
  & x_size, y_size, z_size )

  reductionArrayHost2 = reductionArrayDevice2_turbin_kernel_eqB

  DO i10 = 0, reductionCardinality2-1
    opsDat2Host = opsDat2Host + reductionArrayHost2(i10+1)
  END DO

  deallocate( reductionArrayHost2 )
  istat = cudaDeviceSynchronize()
  call ops_timers_core(t3)
  call ops_set_dirtybit_device(opsArgArray, 2)

  !Timing and data movement
  transfer_total = 0.0_4
  call ops_compute_transfer(3, start_indx, end_indx, opsArg1,transfer)
  transfer_total = transfer_total + transfer
  call setKernelTime(522,userSubroutine,t3-t2,t2-t1,transfer_total,0)

end subroutine

END MODULE
